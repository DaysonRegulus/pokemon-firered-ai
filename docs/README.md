# PokÃ©mon FireRed AI Agent

An AI agent trained to play PokÃ©mon FireRed using the Stable-Baselines3 reinforcement learning framework.

## ğŸ¯ Project Goal

Train reinforcement learning (RL) agents capable of playing PokÃ©mon FireRed effectively, using visual feedback and emulator RAM values as reward signals.

## ğŸ§  Agent Overview

This project uses a CNN-based policy to train the agent, with reward signals engineered from:

- Visual exploration (new areas discovered)
- PokÃ©mon leveling up
- Fainting events (self and opponent)
- Real-time battle statistics (HP, level, etc.)

These signals are derived from direct memory (RAM) reads of the emulator.

## ğŸš€ Getting Started

To run the project, simply execute:

```bash
python FireRedRender.py
```
This will start the training process (or load an existing pre-trained model if available).

All environment setup (gym, stable-retro, reward manager) is handled internally. The script runs in a compact form, assuming dependencies are already installed.

## ğŸ–¥ï¸ Environment

- WSL Ubuntu

- Virtual Environment (venv)

- Python 3.10+

- GPU Acceleration (CUDA supported)

## ğŸ” Workflow

- Parallelized environments for faster training

- Reward management via RAM data

- Model checkpoints for resuming training

## ğŸ“ File Structure

```
Project
|
â”‚â”€â”€FireRedRender.py                         # Main training loop
â”‚â”€â”€FireRedRewardManager.py                  # Custom reward logic from emulator RAM
|â”€â”€PokemonFireRed-GBA_ppo_model_8penv.zip   #Pre-trained model
â”‚
â””â”€â”€â”€Docs
    â”‚â”€â”€README.md
    â”‚â”€â”€License

```

## ğŸ“½ï¸ Media Showcase

Soon

## ğŸ™Œ Acknowledgements

- [Farama Foundation](https://farama.org/) for `stable-retro`
- [MatPoliquin](https://github.com/MatPoliquin) for foundational work on RAM mapping and wrappers
- [Peter Whidden](https://github.com/PWhiddy) for key contributions to retro gaming AI environments

